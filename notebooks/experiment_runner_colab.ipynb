{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Executor do experimento no ambiente do Google Colab\n",
        "\n",
        "## Verificação do ambiente de execução\n",
        "\n",
        "- Valida a GPU\n",
        "- Documenta o ambiente de execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwRbUagbys9a",
        "outputId": "da9223bb-9acf-4835-96a7-c505a6db91be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Feb 18 23:07:45 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "2.19.0\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices(\"GPU\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clonagem do repositório do GitHub\n",
        "\n",
        "- Clona o repositório via `git clone`\n",
        "- Transfere o ambiente de execução para a pasta raiz do repositório"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjYy0F2gZIPR",
        "outputId": "200c6b65-2e69-4fbf-f41c-313508591c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'classification-of-medical-images-using-cnn'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 180 (delta 82), reused 150 (delta 55), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (180/180), 6.13 MiB | 28.15 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "/content/classification-of-medical-images-using-cnn\n",
            "Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n",
            "Switched to a new branch 'develop'\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/amartinsmg/classification-of-medical-images-using-cnn.git\n",
        "%cd /content/classification-of-medical-images-using-cnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Montagem do Google Drive\n",
        "\n",
        "- Monta o Google Drive permitindo que os arquivos presentes nele sejam lidos e escritos\n",
        "- Define o diretório base de onde serão carregados os dados de treino, validação e teste, e onde serão salvos o modelo e os resultados do experimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seXlyTPOwoeP",
        "outputId": "e568039b-8b2a-481e-91a8-998c636192cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "BASE_PATH = \"/content/drive/MyDrive/classification-of-medical-images-using-cnn/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definição de parâmetros gerais\n",
        "\n",
        "- `IMAGE_SIZE`: tamanho para o qual as imagens serão resimensionadas para que o modelo possa analisar\n",
        "- `BATCH_SIZE`: tamanho do lote de imagens que serão analisadas pelo modelo a cada interação\n",
        "- `EPOCHS`: número de vezes que o modelo analisará todas as imagens do conjunto de treinamento\n",
        "- `SEED`: indica como será feito o embaralhamento do conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "- Impporta o pipeline de treinamento\n",
        "- Executa o treinamento e salva o modelo e o histótico de treino na pasta do Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd1FU-SBvyvL",
        "outputId": "2d0a4b6c-46fc-4b4c-f4d8-27b2b4da9762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5216 files belonging to 2 classes.\n",
            "Found 16 files belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1027s\u001b[0m 6s/step - accuracy: 0.7138 - loss: 0.5935 - val_accuracy: 0.5625 - val_loss: 0.6472\n",
            "Epoch 2/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 83ms/step - accuracy: 0.7612 - loss: 0.4680 - val_accuracy: 0.6250 - val_loss: 0.6436\n",
            "Epoch 3/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.7854 - loss: 0.4205 - val_accuracy: 0.6250 - val_loss: 0.6715\n",
            "Epoch 4/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 86ms/step - accuracy: 0.8034 - loss: 0.3967 - val_accuracy: 0.6250 - val_loss: 0.6897\n",
            "Epoch 5/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - accuracy: 0.8156 - loss: 0.3811 - val_accuracy: 0.6250 - val_loss: 0.7058\n",
            "Epoch 6/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - accuracy: 0.8266 - loss: 0.3677 - val_accuracy: 0.6250 - val_loss: 0.6948\n",
            "Epoch 7/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - accuracy: 0.8335 - loss: 0.3540 - val_accuracy: 0.6250 - val_loss: 0.7391\n",
            "Epoch 8/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - accuracy: 0.8345 - loss: 0.3457 - val_accuracy: 0.6250 - val_loss: 0.7710\n",
            "Epoch 9/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - accuracy: 0.8388 - loss: 0.3371 - val_accuracy: 0.6250 - val_loss: 0.7817\n",
            "Epoch 10/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - accuracy: 0.8439 - loss: 0.3299 - val_accuracy: 0.6875 - val_loss: 0.8242\n"
          ]
        }
      ],
      "source": [
        "from src.train import train_pipeline\n",
        "\n",
        "train_pipeline(\n",
        "    base_dir=BASE_PATH,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    seed=SEED,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
