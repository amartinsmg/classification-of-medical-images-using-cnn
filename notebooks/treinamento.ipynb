{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32dd3923",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas\n",
    "\n",
    "- TensorFlow: biblioteca para processamento de dados e contrução de CNN\n",
    "- JSON: biblioteca para codificação e decodificação de no formatpo JavaScript Object Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c964de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import json\n",
    "from os import path, getcwd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe38e2",
   "metadata": {},
   "source": [
    "## Definindo a localização dos dados\n",
    "\n",
    "Verifica se o código está sendo rodado no Google Colab e, se sim, monta o drive no ambiente de execução e aponta a pasta raiz do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37eef14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    BASE_PATH = \"/content/drive/MyDrive/classification-of-medical-images-using-cnn/\"\n",
    "else:\n",
    "    BASE_PATH = path.abspath(path.join(getcwd(), \"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50045afe",
   "metadata": {},
   "source": [
    "Armazena o local onde os dados de treino e validação estão presentes e onde o modelo deve salvar o modelo já treinado, os pesos usados por ele e o histórico de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71300193",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = path.join(BASE_PATH, \"data\", \"train\")\n",
    "VAL_DIR = path.join(BASE_PATH, \"data\", \"val\")\n",
    "MODELS_PATH = path.join(BASE_PATH, \"models\", \"xray_images.keras\")\n",
    "MODEL_WEIGHTS_PATH = path.join(BASE_PATH, \"models\", \"xray_images.weights.h5\")\n",
    "RESULT_PATH = path.join(BASE_PATH, \"results\", \"xray_images.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849340ec",
   "metadata": {},
   "source": [
    "## Definição de parâmetros gerais\n",
    "\n",
    "- `IMAGE_SIZE`: tamanho para o qual as imagens serão resimensionadas para que o modelo possa analisar\n",
    "- `BATCH_SIZE`: tamanho do lote de imagens que serão analisadas pelo modelo a cada interação\n",
    "- `EPOCHS`: número de vezes que o modelo analisará todas as imagens do conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28935b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2b0abd",
   "metadata": {},
   "source": [
    "## Carregamento do dataset\n",
    "\n",
    "- `image_size`: resimensiona as imagens\n",
    "- `batch_size`: define o número de imagens por lote\n",
    "- `label_mode`: separa todas as imagens em duas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec634f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 files belonging to 2 classes.\n",
      "Found 16 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, label_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DIR, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, label_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065ca51",
   "metadata": {},
   "source": [
    "##  Pré processamento das imagens\n",
    "\n",
    "#### Noramalização\n",
    "\n",
    "- `normalization_layer`: deffine para que os pixels da imagem sejam normalizados para valores entre 0 e 1\n",
    "\n",
    "- Realiza a normalização nos conjuntos de treino e de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52dc3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "train_data = train_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_data = val_data.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4f21b",
   "metadata": {},
   "source": [
    "#### Denfinindo e aplicando padrões de aumentação\n",
    "\n",
    "- `RandomFlip`: inverte a imagem na horizontal aleatoriamente\n",
    "- `RandomRotation`: gira a imagem aleatoriamente (0.05 equivale a até 5% da circunferência aprox. 18 graus)\n",
    "- `RandomZoom`: amplia ou reduz na imagem aleatoriamente (0.1 equivale a até 10% do tamanho da imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44a79e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.05),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5016df20",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "Realiza o data augmentation apenas no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "737771db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973f61b",
   "metadata": {},
   "source": [
    "## Otimização do desempenho\n",
    "\n",
    "O AUTOTUNE permite que a biblioteca do TensorFlow decida sozinho quantos dados carregar com antecedência, quando carregar e quanto de paralelismo usar, para se ajustar automaticamente para o melhor desempenho no hardware disponível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0204644",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6870d",
   "metadata": {},
   "source": [
    "## Carregamento do Modelo Pré-treinado (transfer learning)\n",
    "\n",
    "- Carrega o modelo base ResNet50 pré-treinada no Imagenet\n",
    "\n",
    "- Congela as camadas da rede base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76b91eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd65209",
   "metadata": {},
   "source": [
    "## Construção do modelo final\n",
    "\n",
    "Diz ao modelo que ele receberá imagens de 224X224 pixels com 3 canais de cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02be18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224,224,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509725f",
   "metadata": {},
   "source": [
    "- `x`: representa os dados intermediários do processamento\n",
    "- `training=False`: usdo para impedir instabilidades no treinamento ou destruição do conhecimento prévio do modelo pré-treinado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8eda673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model(inputs, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5ff26",
   "metadata": {},
   "source": [
    "Reduz a dimensionabilidade das características extraídas  pelo ResNet:\n",
    "- A rede neural desenha vários mapas das características da imagem\n",
    "- O `GlobalAveragePooling2D` tira a média de cada um destes mapas\n",
    "- Reduz o número de parâmetros, melhora a generalização e diminui overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3778e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f3a1c",
   "metadata": {},
   "source": [
    "É uma camada de decisão\n",
    "- Combina as características resumidas pelo `GlobalAveragePooling2D`, aprende as relações\n",
    "- 128 indica o número de neurônios pelos quais as informações pasarão\n",
    "  - números menores fazem o modelo decidir muito rápido, sem \"raciocinar\" direito\n",
    "  - números maiores podem tornar o modelo pesado demais, além de poderem fazer ele \"se confundir\"\n",
    "- O ReLU (Rectified Linear Unit) age como um filtro de relevância\n",
    "  - valores negativos são transformados em zero - informações\n",
    "  - valores ppositivos são mantidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81238b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(128, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad9a128",
   "metadata": {},
   "source": [
    "Outra camada de decisão\n",
    "- O valor 1 indica que deve haver apenas uma saída\n",
    "- O `sigmoid` faz o modelo decidir entre uma resposta binária\n",
    "  - 0.34 vira 0\n",
    "  - 0.73 vira 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d8b8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b6155",
   "metadata": {},
   "source": [
    "Informa ao modelo quais tipos de dados serão sua entrada e o tipo de saída esperada após o processamento, ele automaticamente conecta todas as epatas itermediárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94edf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48be4ed3",
   "metadata": {},
   "source": [
    "## Compilação do Modelo\n",
    "\n",
    "- `optimizer` indica ao modelo como ajustar seus erros\n",
    "  - Adam é um otimizador rápido e estável, bom para a maioria dos problemas\n",
    "- `loss` é uma forma de medir o quão longe o modelo estava da resosta certa\n",
    "  - `binary_crossentropy` é usada quando há duas classes e a saída é uma probabilidade entre 0 e 1\n",
    "  - Pune mais erros confiantes que erros \"em dúvida\"\n",
    "- `metrics` permite a acompanhar o desempenho do modelo, se ele está realmente aprendendo\n",
    "  - `accuracy` é basicamente a precisão do modelo, quantas previsões ele acertou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80dd2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143feb4b",
   "metadata": {},
   "source": [
    "## Treinamento do modelo\n",
    "\n",
    "Indica ao modelo o conjunto de treinamento, de validação e o número de épocas (quantas vezes o modelo vê todo o conjunto de dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "548894e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 527ms/step - accuracy: 0.7439 - loss: 0.5438 - val_accuracy: 0.5000 - val_loss: 0.9990\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.7742 - loss: 0.4582 - val_accuracy: 0.5625 - val_loss: 1.0368\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.7991 - loss: 0.4101 - val_accuracy: 0.5625 - val_loss: 1.0473\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.8135 - loss: 0.3839 - val_accuracy: 0.5625 - val_loss: 1.0653\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - accuracy: 0.8246 - loss: 0.3667 - val_accuracy: 0.6250 - val_loss: 1.0745\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.8313 - loss: 0.3525 - val_accuracy: 0.6250 - val_loss: 1.0427\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8361 - loss: 0.3423 - val_accuracy: 0.6250 - val_loss: 1.0178\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8447 - loss: 0.3298 - val_accuracy: 0.6250 - val_loss: 1.0170\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.8512 - loss: 0.3187 - val_accuracy: 0.6250 - val_loss: 0.9866\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8583 - loss: 0.3081 - val_accuracy: 0.6250 - val_loss: 0.9942\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, validation_data=val_data, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339b39b",
   "metadata": {},
   "source": [
    "## Salvando o modelo em disco \n",
    "\n",
    "Salva o modelo já treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7988d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODELS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985773de",
   "metadata": {},
   "source": [
    "Salva os pesos atribuídos pelo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d65365e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(MODEL_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48749609",
   "metadata": {},
   "source": [
    "Salva o histórico do treinamento como um arquivo no formato JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23917497",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "with open(RESULT_PATH, \"w\") as f:\n",
    "    json.dump(history_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
