{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a7f6e4",
   "metadata": {},
   "source": [
    "# Teste do modelo usando imagens radiográficas\n",
    "\n",
    "## Importando as bibliotecas\n",
    "\n",
    "- OS: biblioteca para interação com sistema operacional\n",
    "- SYS: biblioteca focada na interação com o interpretador do python\n",
    "- TensorFlow: biblioteca para processamento de dados e contrução de CNN\n",
    "- Keras: API de deep learining de alto nível executada sobre o TensorFlow\n",
    "- Numpy: biblioteca para computação científica com arrays e matrizes multidimensionais\n",
    "- SciKit Learn: biblioteca para ML com ferramentas para análise preditiva de dados \n",
    "- JSON: biblioteca para codificação e decodificação de no formatpo JavaScript Object Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1dd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a619d1",
   "metadata": {},
   "source": [
    "## Definindo a localização dos dados\n",
    "\n",
    "Verifica se o código está sendo rodado no Google Colab e, se sim, monta o drive no ambiente de execução e aponta a pasta raiz do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5463a931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    BASE_PATH = \"/content/drive/MyDrive/classification-of-medical-images-using-cnn/\"\n",
    "else:\n",
    "    BASE_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01ebc4",
   "metadata": {},
   "source": [
    "- Armazena o local onde os dados de teste estão presentes\n",
    "- Armazena o local onde o modelo já treinado está salvo\n",
    "- Armazena o local onde as métricas apuradas pelo teste ficarão salvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614ff27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = os.path.join(BASE_PATH, \"data\", \"test\")\n",
    "MODEL_PATH = os.path.join(BASE_PATH, \"models\", \"xray_images.keras\")\n",
    "METRICS_PATH = os.path.join(BASE_PATH, \"results\", \"metrics.json\")\n",
    "\n",
    "os.makedirs(os.path.dirname(METRICS_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa29159",
   "metadata": {},
   "source": [
    "## Carregamento do dataset\n",
    "\n",
    "- Carrega as imagens de teste:\n",
    "  - `image_size`: redimensiona as imagens\n",
    "  - `batch_size`: define o número de imagens por lote\n",
    "  - `label_mode`: separa todas as imagens em duas classes\n",
    "  - `shuffle`: define que as imagens não serão embaralhadas\n",
    "\n",
    "- Em seguida aplica normalização dos pixels e otimiza o desemepnho usando AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38113d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "test_data = test_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "test_data = test_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec6aae",
   "metadata": {},
   "source": [
    "## Teste do modelo\n",
    "\n",
    "- Carrega o modelo do disco\n",
    "- Realiza o teste do modelo e salva as métricas do teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413f5835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6s/step - accuracy: 0.7980 - loss: 0.4899\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "metrics = model.evaluate(test_data, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5184020b",
   "metadata": {},
   "source": [
    "## Coleta das Previsões do Modelo\n",
    "\n",
    "- O loop `for` percorre todo o conjunto de teste em lotes (batches)\n",
    "  - A função `predict` colhe o palpite do modelo em relação às imagens com um número variando de 0 a 1 que quanto mais próximo de 0, mais o modelo acredita se tratar da classe 0, quanto mais próximo 1, da classe 1\n",
    "  - Armazena as classes das imagens (0 ou 1) em `y_true`, transformando os tensores em arrays\n",
    "  - Armazena os palpites do modelo em `y_scores` \n",
    "  - A função `flatten` é usada para transformar matrizes multidimensionais em arrays unidimensionais\n",
    "- A função `np.array` transforma os dados em arrays do numpy\n",
    "- `y_pred` usa os palpites do modelo para definir as classes 0 ou 1:\n",
    "  - Se o palpite for maior que `0.5`, vira 1\n",
    "  - Se for menor ou igual a `0.5`, vira 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be06da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_scores = []\n",
    "\n",
    "for images, labels in test_data:\n",
    "    predictions = model.predict(images)\n",
    "    y_true.extend(labels.numpy().flatten())\n",
    "    y_scores.extend(predictions.flatten())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_scores = np.array(y_scores)\n",
    "\n",
    "y_pred = (y_scores > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2fbe4f",
   "metadata": {},
   "source": [
    "## Cálculo de métricas que dependem da \"decisão\" do modelo\n",
    "\n",
    "- Estas métricas dependem das decisões do modelo (`y_pred`) entre uma das classes binárias, i.e., qual classe o modelo previu\n",
    "\n",
    "- A matriz de consusão é calculada pela biblioteca do SciKit e a partir dela são revelados os seguintes dados:\n",
    "  - Verdadeiros Negativos (TN): quantos casos negativos (classe 0) o modelo previu corretamente\n",
    "  - Falsos Positivos (FP): quantos casos negativos o modelo previu de forma errada\n",
    "  - Falsos Negativos (FN): quantos casos positivos (classe 1) o modelo previu de forma errada\n",
    "  - Verdadeiros Positivos (TP): quantos casos positivos o modelo previu corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8eda361",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix.ravel().tolist()\n",
    "\n",
    "metrics[\"confusion_matrix\"] = {\n",
    "    \"TN\": int(TN),\n",
    "    \"FP\": int(FP),\n",
    "    \"FN\": int(FN),\n",
    "    \"TP\": int(TP),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e2989",
   "metadata": {},
   "source": [
    "- A \"precision\" mede: do total de previsões positivas (classe 1) quantas realmente eram positivas\n",
    "\n",
    "  $$ \\frac{Verdadeiros \\, Positivos}{Verdadeiros \\, Positivos + Falsos \\, Positivos} $$\n",
    "\n",
    "- A \"sensibility\" ou \"recall\" mede: do total de casos positivos, quantos o modelo conseguiu identificar corretamente\n",
    "\n",
    "  $$ \\frac{Verdadeiros \\, Positivos}{Verdadeiros \\, Positivos + Falsos \\, Negativos} $$\n",
    "\n",
    "- A \"specificity\" mede: do total de casos negativos (classe 0), quantos o modelo conseguiu identificar corretamente\n",
    "\n",
    "  $$ \\frac{Verdadeiros \\, Negativos}{Verdadeiros \\, Negativos + Falsos \\, Positivos} $$\n",
    "\n",
    "- O score F1 é basicamente a média harmônica entre a precisão e a sensibilidade, que acaba privilegiando o valor mais baixo entre elas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c1f1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"precision\"] =  TP / (TP + FP) if (TP + FP) else 0\n",
    "metrics[\"sensibility\"] = TP / (TP + FN)\n",
    "metrics[\"specificity\"] = TN / (TN + FP)\n",
    "metrics[\"f1_score\"] = sklearn.metrics.f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c624ca",
   "metadata": {},
   "source": [
    "## Salvamento das métricas de avaliação\n",
    "\n",
    "Salva as métricas de avaliação em disco no formato JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cdcba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"accuracy\": 0.8365384340286255,\n",
      "    \"loss\": 0.3980501890182495,\n",
      "    \"confusion_matrix\": {\n",
      "        \"TN\": 179,\n",
      "        \"FP\": 55,\n",
      "        \"FN\": 47,\n",
      "        \"TP\": 343\n",
      "    },\n",
      "    \"precision\": 0.8618090452261307,\n",
      "    \"sensibility\": 0.8794871794871795,\n",
      "    \"specificity\": 0.7649572649572649,\n",
      "    \"f1_score\": 0.8705583756345178\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
