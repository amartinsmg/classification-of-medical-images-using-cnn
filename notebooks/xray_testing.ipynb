{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1dd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5463a931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    BASE_PATH = \"/content/drive/MyDrive/classification-of-medical-images-using-cnn/\"\n",
    "else:\n",
    "    BASE_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614ff27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = os.path.join(BASE_PATH, \"data\", \"test\")\n",
    "MODEL_PATH = os.path.join(BASE_PATH, \"models\", \"xray_images.keras\")\n",
    "METRICS_PATH = os.path.join(BASE_PATH, \"results\", \"metrics.json\")\n",
    "\n",
    "os.makedirs(os.path.dirname(METRICS_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38113d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "test_data = test_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "test_data = test_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413f5835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step - accuracy: 0.7980 - loss: 0.4899\n",
      "{\n",
      "    \"accuracy\": 0.8365384340286255,\n",
      "    \"loss\": 0.3980506956577301\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "metrics = model.evaluate(test_data, return_dict=True)\n",
    "\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be06da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_scores = []\n",
    "\n",
    "for images, labels in test_data:\n",
    "    predictions = model.predict(images)\n",
    "\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_scores.extend(predictions.flatten())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_scores = np.array(y_scores)\n",
    "\n",
    "y_pred = (y_scores > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eda361",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"precision\"] = sklearn.metrics.precision_score(y_true, y_pred)\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix.ravel().tolist()\n",
    "\n",
    "metrics[\"confusion_matrix\"] = {\n",
    "    \"TN\": int(TN),\n",
    "    \"FP\": int(FP),\n",
    "    \"FN\": int(FN),\n",
    "    \"TP\": int(TP),\n",
    "}\n",
    "\n",
    "metrics[\"f1_score\"] = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "metrics[\"sensibility\"] = TP / (TP + FN)\n",
    "metrics[\"specificity\"] = TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cdcba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"accuracy\": 0.8365384340286255,\n",
      "    \"loss\": 0.3980506956577301,\n",
      "    \"precision\": 0.8618090452261307,\n",
      "    \"confusion_matrix\": {\n",
      "        \"TN\": 179,\n",
      "        \"FP\": 55,\n",
      "        \"FN\": 47,\n",
      "        \"TP\": 343\n",
      "    },\n",
      "    \"f1_score\": 0.8705583756345178,\n",
      "    \"sensibility\": 0.8794871794871795,\n",
      "    \"specificity\": 0.7649572649572649\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
